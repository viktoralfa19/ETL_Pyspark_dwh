{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExceptionManager import ExceptionManager\n",
    "from HDFSContext import HDFSContext\n",
    "from GenericDataFrame import GenericDataFrame\n",
    "from DBContextDw import DBContextDw\n",
    "from EtlDimensionAL import EtlDimensionAL\n",
    "from Queries import Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as Funct\n",
    "from pyspark.sql.functions import regexp_replace,row_number, col,upper,udf\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETLAgenteBL():\n",
    "    \"\"\"Lógica de negocio para el ingreso de datos en la dimensión de AGENTES\"\"\"\n",
    "    def __init__ (self):\n",
    "        dbContext = DBContextDw(Database='dwh_sirio',urlDriver='/home/jovyan/work/postgresql-42.2.12.jar')\n",
    "        self._accesoDatos = EtlDimensionAL(dbContext)   \n",
    "        self.spark = SparkSession.builder.appName('Sirio').getOrCreate()  \n",
    "        self.catalogoDW= None\n",
    "        \n",
    "    def Elt_main(self):\n",
    "        try:\n",
    "            \"\"\"Método que procesa todo el flujo de proceso del ETL.\"\"\"\n",
    "            print('---- Proceso de ETL de Dimensiones de AGENTE ---- \\n')\n",
    "            print('DATAWAREHOUSE: dwh_sirio')\n",
    "            print('DIMENSIÓN: dim_agente \\n')\n",
    "\n",
    "            print('1. Extracción de datos')\n",
    "            extract_data = self.Extract_data_agentes()\n",
    "            \n",
    "            print('2. Transformación de datos')\n",
    "            transform_data = self.Transform_data(extract_data)\n",
    "            \n",
    "            print('3. Cargar  datos\\n')\n",
    "            self.Load_data(transform_data,'cen_dws.dim_agente')\n",
    "        except Exception as error:\n",
    "            ExceptionManager.Treatment(error)\n",
    "    \n",
    "    def Extract_data_agentes (self):\n",
    "        \"\"\"Método que realiza la extracción de datos de Agentes desde el HDFS\"\"\"\n",
    "        self._genericDataFrame=GenericDataFrame(HDFSContext(DataBase='SIVO')) \n",
    "        agentes = self._genericDataFrame.GetDataHdfs('AGENTES','file_AGENTE_*')\n",
    "        agentes = agentes.select(col('EMPRESA_CODIGO').alias('agt_empresa_id_bk'),upper(col('EMPRESA_NOMBRE')).alias('agt_empresa'),\n",
    "                                 col('REGION_CODIGO').alias('agt_region_id_bk'),upper(col('REGION_NOMBRE')).alias('agt_region'),\n",
    "                                 col('UNEGOCIO_CODIGO').alias('agt_und_negocio_id_bk'),upper(col('UNEGOCIO_NOMBRE')).alias('agt_und_negocio'),\n",
    "                                 col('CLASE_UNEGOCIO_CODIGO').alias('agt_clase_unegocio_id_bk'),upper(col('CLASE_UNEGOCIO_NOMBRE')).alias('agt_clase_unegocio'),\n",
    "                                 col('ESTACION_CODIGO').alias('agt_estacion_id_bk'),upper(col('ESTACION_NOMBRE')).alias('agt_estacion'),\n",
    "                                 col('TIPO_ESTACION_CODIGO').alias('agt_tipo_estacion_id_bk'),upper(col('TIPO_ESTACION_NOMBRE')).alias('agt_tipo_estacion'),\n",
    "                                 col('GGENERACION_CODIGO').alias('agt_grupo_gen_id_bk'),upper(col('GGENERACION_NOMBRE')).alias('agt_grupo_gen'),\n",
    "                                 col('VOLTAJE_CODIGO').alias('agt_voltaje_id_bk'),col('VOLTAJE_NOMBRE').alias('agt_voltaje'),\n",
    "                                 col('TIPO_ID').alias('agt_tipo_elemento_id_bk'),upper(col('TIPO')).alias('agt_tipo_elemento'),\n",
    "                                 col('ELEMENTO_CODIGO').alias('agt_elemento_id_bk'),upper(col('ELEMENTO_NOMBRE')).alias('agt_elemento'),\n",
    "                                 col('OPERACION_COMERCIAL').alias('agt_operacion_comercial').cast('timestamp'))\n",
    "        \n",
    "        return agentes\n",
    "    \n",
    "    def Transform_data (self, extract_data):\n",
    "        \"\"\"Método que transforma los datos obtenidos desde el HDFS, identifica si es ingreso nuevo o actualización\"\"\"\n",
    "        paramReplace = ['NO VIGENTE','NO USAR','\\)','\\(','\\.','CENTRAL','CELEC EP -','CENACE -','CNEL EP','EE ','XM SA ESP']        \n",
    "        valueReplace=  ['','','','','','','','','','EE. ','XM S.A. E.S.P.']\n",
    "\n",
    "        maxPk = self._accesoDatos.GetMaxPkDimension('SELECT MAX(agt_id_pk) pk FROM cen_dws.dim_agente')   \n",
    "        self.catalogoDW = self._accesoDatos.GetAllData('cen_dws.dim_agente')\n",
    "        fecha_carga = datetime.datetime.today()\n",
    "\n",
    "        for toReplace, replacement in zip(paramReplace, valueReplace):\n",
    "            extract_data = extract_data\\\n",
    "            .select(extract_data.agt_empresa_id_bk,\n",
    "                    Funct.trim(regexp_replace(extract_data.agt_empresa, toReplace, replacement)).alias('agt_empresa'),\n",
    "                    extract_data.agt_region_id_bk, \n",
    "                    extract_data.agt_region,\n",
    "                    extract_data.agt_und_negocio_id_bk, \n",
    "                    Funct.trim(regexp_replace(extract_data.agt_und_negocio, toReplace, replacement)).alias('agt_und_negocio'),\n",
    "                    extract_data.agt_clase_unegocio_id_bk, \n",
    "                    extract_data.agt_clase_unegocio,\n",
    "                    extract_data.agt_estacion_id_bk, \n",
    "                    Funct.trim(regexp_replace(extract_data.agt_estacion, toReplace, replacement)).alias('agt_estacion'),\n",
    "                    extract_data.agt_tipo_estacion_id_bk, \n",
    "                    extract_data.agt_tipo_estacion,\n",
    "                    extract_data.agt_grupo_gen_id_bk, \n",
    "                    Funct.trim(regexp_replace(extract_data.agt_grupo_gen, toReplace, replacement)).alias('agt_grupo_gen'),\n",
    "                    extract_data.agt_voltaje_id_bk, \n",
    "                    extract_data.agt_voltaje,\n",
    "                    extract_data.agt_tipo_elemento_id_bk, \n",
    "                    extract_data.agt_tipo_elemento,\n",
    "                    extract_data.agt_elemento_id_bk, \n",
    "                    Funct.trim(regexp_replace(extract_data.agt_elemento, toReplace, replacement)).alias('agt_elemento'),\n",
    "                    extract_data.agt_operacion_comercial)\n",
    "\n",
    "        extract_data = extract_data.groupby('agt_empresa_id_bk','agt_empresa','agt_region_id_bk','agt_region','agt_und_negocio_id_bk','agt_und_negocio',\n",
    "                 'agt_clase_unegocio_id_bk','agt_clase_unegocio','agt_estacion_id_bk','agt_estacion','agt_tipo_estacion_id_bk',\n",
    "                 'agt_tipo_estacion','agt_grupo_gen_id_bk','agt_grupo_gen','agt_voltaje_id_bk','agt_voltaje','agt_tipo_elemento_id_bk',\n",
    "                 'agt_tipo_elemento','agt_elemento_id_bk','agt_elemento')\\\n",
    "        .agg(Funct.min('agt_operacion_comercial').alias('agt_operacion_comercial')).distinct()\n",
    "        \n",
    "        if self.catalogoDW.count()==0: \n",
    "            catalogos = extract_data.select((maxPk+row_number().over(Window.partitionBy()\\\n",
    "                            .orderBy(extract_data.agt_empresa_id_bk,\n",
    "                                     extract_data.agt_und_negocio_id_bk,\n",
    "                                     extract_data.agt_clase_unegocio_id_bk,\n",
    "                                     extract_data.agt_estacion_id_bk,\n",
    "                                     extract_data.agt_elemento_id_bk))).alias('agt_id_pk'),'*', \n",
    "                            Funct.concat(Funct.lit(fecha_carga)).cast('timestamp').alias('fecha_carga'))\n",
    "        else:\n",
    "            # Con el query se pretende verificar que registros son nuevos y que registros son los que han sufrido modificaciones                \n",
    "            data_to_compare = extract_data.join(self.catalogoDW,\n",
    "                                                (extract_data.agt_empresa_id_bk==self.catalogoDW.agt_empresa_id_bk) &\\\n",
    "                                                (extract_data.agt_und_negocio_id_bk==self.catalogoDW.agt_und_negocio_id_bk) &\\\n",
    "                                                (extract_data.agt_clase_unegocio_id_bk==self.catalogoDW.agt_clase_unegocio_id_bk) &\\\n",
    "                                                (extract_data.agt_estacion_id_bk==self.catalogoDW.agt_estacion_id_bk) &\\\n",
    "                                                (extract_data.agt_elemento_id_bk==self.catalogoDW.agt_elemento_id_bk), how='left')\\\n",
    "                                        .select(Funct.when(self.catalogoDW.agt_id_pk.isNull(),0).otherwise(self.catalogoDW.agt_id_pk).alias(\"agt_id_pk\"), \n",
    "                                                extract_data.agt_empresa_id_bk, extract_data.agt_empresa, \n",
    "                                                extract_data.agt_region_id_bk, extract_data.agt_region, \n",
    "                                                extract_data.agt_und_negocio_id_bk, extract_data.agt_und_negocio,\n",
    "                                                extract_data.agt_clase_unegocio_id_bk, extract_data.agt_clase_unegocio, \n",
    "                                                extract_data.agt_estacion_id_bk, extract_data.agt_estacion, \n",
    "                                                extract_data.agt_tipo_estacion_id_bk, extract_data.agt_tipo_estacion,\n",
    "                                                extract_data.agt_grupo_gen_id_bk, extract_data.agt_grupo_gen,\n",
    "                                                extract_data.agt_voltaje_id_bk, extract_data.agt_voltaje,\n",
    "                                                extract_data.agt_tipo_elemento_id_bk, extract_data.agt_tipo_elemento,\n",
    "                                                extract_data.agt_elemento_id_bk, extract_data.agt_elemento,\n",
    "                                                extract_data.agt_operacion_comercial)                \n",
    "\n",
    "            # Identificación de registros nuevos que deben ser insertados en el DWH\n",
    "            dataNw = data_to_compare.filter(data_to_compare.agt_id_pk==0).drop('agt_id_pk')\n",
    "\n",
    "            catalogos = dataNw.select((maxPk+row_number().over(Window.partitionBy()\\\n",
    "                                                               .orderBy(dataNw.agt_empresa_id_bk,\n",
    "                                                                        dataNw.agt_und_negocio_id_bk,\n",
    "                                                                        dataNw.agt_clase_unegocio_id_bk,\n",
    "                                                                        dataNw.agt_estacion_id_bk,\n",
    "                                                                        dataNw.agt_elemento_id_bk))).alias('agt_id_pk'),\n",
    "                                      '*',Funct.concat(Funct.lit(fecha_carga)).cast('timestamp').alias('fecha_carga'))\n",
    "\n",
    "            # Identificación de registros que han sufrido cambios en la base transaccional y deben ser modificados en el DW\n",
    "            dataMdf = data_to_compare.filter(data_to_compare.agt_id_pk!=0)\n",
    "\n",
    "            data_modificada = dataMdf.exceptAll(self.catalogoDW.drop('fecha_carga'))\\\n",
    "            .select('*',Funct.concat(Funct.lit(fecha_carga)).cast(\"timestamp\").alias(\"fecha_carga\"))\n",
    "\n",
    "            catalogos = catalogos.union(data_modificada)\n",
    "\n",
    "        if catalogos.count()==0: \n",
    "            catalogos = None\n",
    "        return catalogos\n",
    "        \n",
    "            \n",
    "        \n",
    "    def Load_data(self,transform_data, table):\n",
    "        \"\"\"Método que realiza la carga de datos en la bodega de datos DW.\"\"\"\n",
    "        if transform_data is not None: \n",
    "            if self.catalogoDW.count() == 0:\n",
    "                result = self._accesoDatos.InsertDimension(transform_data, table)\n",
    "            else :\n",
    "                result = self.Load_Upsert_data(transform_data)\n",
    "                result.show()\n",
    "                result = True\n",
    "       \n",
    "            if result == True: \n",
    "                mensaje = \" **** EXITOSO: Datos insertados correctamente en la dimensión de {0}.**** \".format(table)\n",
    "            else: \n",
    "                mensaje = \" **** ERROR: Error al insertar datos en la dimensión de {0}.****\".format(table)\n",
    "        else :\n",
    "            mensaje = \" **** WARNING: No existen datos para insertar en la dimensión {0}.****\".format(table)\n",
    "    \n",
    "        print(mensaje) \n",
    "        \n",
    "    def Load_Upsert_data(self,transform_data):\n",
    "        \"\"\"Método que realiza la lógica de creación de queries para el método upsert. \"\"\"\n",
    "        result_transact = []\n",
    "        transform_data_map = transform_data.rdd.map(lambda x: (x.agt_id_pk, [x.agt_empresa_id_bk, x.agt_empresa, \n",
    "                                                                             x.agt_region_id_bk, x.agt_region,\n",
    "                                                                             x.agt_und_negocio_id_bk, x.agt_und_negocio,\n",
    "                                                                             x.agt_clase_unegocio_id_bk, x.agt_clase_unegocio,\n",
    "                                                                             x.agt_estacion_id_bk, x.agt_estacion,\n",
    "                                                                             x.agt_tipo_estacion_id_bk, x.agt_tipo_estacion,\n",
    "                                                                             x.agt_grupo_gen_id_bk, x.agt_grupo_gen,\n",
    "                                                                             x.agt_voltaje_id_bk, x.agt_voltaje,\n",
    "                                                                             x.agt_tipo_elemento_id_bk, x.agt_tipo_elemento,\n",
    "                                                                             x.agt_elemento_id_bk, x.agt_elemento,\n",
    "                                                                             x.agt_operacion_comercial,x.fecha_carga]))\n",
    "        \n",
    "        querys_data_insert = transform_data_map.map(lambda x: Queries.Upsert_Query_Dim_Agente(x))\n",
    "        #for index in querys_data_insert.collect():\n",
    "        #    print(index[0],index[1])\n",
    "        for index in querys_data_insert.collect():\n",
    "            res = []\n",
    "            pk = index[0]\n",
    "            query = index[1]\n",
    "\n",
    "            result = self._accesoDatos.UpsertDimension(query)\n",
    "\n",
    "            res.extend([pk,result])\n",
    "            result_transact.append(res)            \n",
    "            \n",
    "        schema = StructType([\n",
    "                StructField(\"pk\", IntegerType(),False),\n",
    "                StructField(\"Result\", BooleanType(),False)\n",
    "            ])\n",
    "        \n",
    "        result_transact =  self._genericDataFrame.spark.createDataFrame(result_transact,schema=schema)\n",
    "        \n",
    "        return result_transact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "etl = ETLAgenteBL()\n",
    "etl.Elt_main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
